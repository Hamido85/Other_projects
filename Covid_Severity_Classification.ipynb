{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "Our dataset contains `126 rows and 19476 columns`. The objective is to develop a supervised learning model to predict\n",
    "severe COVID-19 hospital admissions by using as predictors the genome sequencing of patients.\n",
    "Since our dataset is high dimensional data which contains 126 rows and 19476 columns, we will need to reduce the dataset dimensions so we will be able to reduce the complexity and computaional time.\n",
    "- __We will apply two methods to reduce the dimensions :__\n",
    "\n",
    "__1- PCA__\n",
    "\n",
    "__2- Feature selection using RandomForest__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Processing First Method using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df=pd.read_csv('covid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Severity</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>39</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.17</td>\n",
       "      <td>363.01</td>\n",
       "      <td>19.17</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2</td>\n",
       "      <td>63</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.20</td>\n",
       "      <td>399.80</td>\n",
       "      <td>15.72</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3</td>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.62</td>\n",
       "      <td>430.35</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4</td>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.88</td>\n",
       "      <td>209.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5</td>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.96</td>\n",
       "      <td>272.91</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19476 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample  Age   Sex Severity  A1BG  A1CF   A2M  A2ML1  A3GALT2  A4GALT  ...  \\\n",
       "0     C1   39  male   NonICU  0.49  0.00  0.21   0.04     0.07     0.0  ...   \n",
       "1     C2   63  male   NonICU  0.29  0.00  0.14   0.00     0.00     0.0  ...   \n",
       "2     C3   33  male   NonICU  0.26  0.00  0.03   0.02     0.00     0.0  ...   \n",
       "3     C4   49  male   NonICU  0.45  0.01  0.09   0.07     0.00     0.0  ...   \n",
       "4     C5   49  male   NonICU  0.17  0.00  0.00   0.05     0.07     0.0  ...   \n",
       "\n",
       "   ZWILCH  ZWINT  ZXDA  ZXDB   ZXDC  ZYG11A  ZYG11B     ZYX  ZZEF1  ZZZ3  \n",
       "0    2.84   4.22  0.95  1.63  15.51    0.06    8.17  363.01  19.17  6.05  \n",
       "1    3.55  12.15  0.60  1.15  15.62    0.14    8.20  399.80  15.72  4.12  \n",
       "2    1.34   2.79  0.18  0.32  17.67    0.28    3.62  430.35  13.95  1.81  \n",
       "3    3.71   5.87  1.40  2.21  15.61    0.27    7.88  209.25  14.78  7.15  \n",
       "4    1.44   4.46  0.28  0.55   9.34    0.07    5.96  272.91   8.69  2.70  \n",
       "\n",
       "[5 rows x 19476 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the sample feature from dataset since its not important\n",
    "df.drop('Sample',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         0\n",
       "Sex         0\n",
       "Severity    0\n",
       "A1BG        0\n",
       "A1CF        0\n",
       "           ..\n",
       "ZYG11A      0\n",
       "ZYG11B      0\n",
       "ZYX         0\n",
       "ZZEF1       0\n",
       "ZZZ3        0\n",
       "Length: 19475, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there is missing values in the dataframe\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the count missing values in the dataframe\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have 2 categorical features in the dataset, so we need to see the proportions of gender and Severity so we will maintain the same proportions when we split the data into train and test. for that we will use Stratify sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male       74\n",
       "female     51\n",
       "unknown     1\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the Gender proportion of the data\n",
    "df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ICU       66\n",
       "NonICU    60\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the target feature 'Severity' proportion of the data\n",
    "df.Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have one unkown gender, we will fill it with the mode which is male the most frequent class \n",
    "df['Sex'].replace({'unknown':'male'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      75\n",
       "female    51\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we will create the Stratify samplming which will split the data in the train and test based on the shared characteristics or attributes of the members in the gender and Severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male ICU         0.333333\n",
       "male NonICU      0.261905\n",
       "female NonICU    0.214286\n",
       "female ICU       0.190476\n",
       "Name: Stratify, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stratify']=df['Sex']+\" \"+df['Severity']\n",
    "(df['Stratify'].value_counts() / len(df)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__ that we have `33% of our data are male and ICU` ,`26% of our data male NonICU`, `21% female NonICU` and last `19% female ICU`.\n",
    "We will take on consideration those proportions when we split the data into train and test. its very important to train the model and test it on the same proportions in order to avoid the bais and imbalance splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        male NonICU\n",
       "1        male NonICU\n",
       "2        male NonICU\n",
       "3        male NonICU\n",
       "4        male NonICU\n",
       "           ...      \n",
       "121      male NonICU\n",
       "122    female NonICU\n",
       "123    female NonICU\n",
       "124      male NonICU\n",
       "125         male ICU\n",
       "Name: Stratify, Length: 126, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stratify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it in seperate list to use it when we split the data\n",
    "Stratify=df['Stratify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop this column from our dataset\n",
    "df.drop('Stratify',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we noticed there are 1249 dublicated columns which need to be removed\n",
    "df2= df.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Severity</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.17</td>\n",
       "      <td>363.01</td>\n",
       "      <td>19.17</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>399.8</td>\n",
       "      <td>15.72</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.62</td>\n",
       "      <td>430.35</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.88</td>\n",
       "      <td>209.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.96</td>\n",
       "      <td>272.91</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>63</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.58</td>\n",
       "      <td>447.14</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.57</td>\n",
       "      <td>748.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>14.93</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>437.62</td>\n",
       "      <td>10.34</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>NonICU</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>369.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "      <td>ICU</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>577.13</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 18226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Severity  A1BG  A1CF   A2M A2ML1 A3GALT2 A4GALT A4GNT  ...  \\\n",
       "0    39    male   NonICU  0.49   0.0  0.21  0.04    0.07    0.0  0.03  ...   \n",
       "1    63    male   NonICU  0.29   0.0  0.14   0.0     0.0    0.0  0.05  ...   \n",
       "2    33    male   NonICU  0.26   0.0  0.03  0.02     0.0    0.0  0.07  ...   \n",
       "3    49    male   NonICU  0.45  0.01  0.09  0.07     0.0    0.0   0.0  ...   \n",
       "4    49    male   NonICU  0.17   0.0   0.0  0.05    0.07    0.0   0.0  ...   \n",
       "..   ..     ...      ...   ...   ...   ...   ...     ...    ...   ...  ...   \n",
       "121  63    male   NonICU   0.3   0.0  0.02  0.02     0.0    0.0   0.0  ...   \n",
       "122  42  female   NonICU   0.7   0.0  0.02  0.01     0.0    0.0   0.0  ...   \n",
       "123  32  female   NonICU  0.75   0.0  0.27   0.0    0.06    0.0   0.0  ...   \n",
       "124  62    male   NonICU   2.8   0.0  0.04   0.0     0.0    0.0   0.0  ...   \n",
       "125  36    male      ICU  0.22   0.0  0.28   0.0     0.0    0.0   0.0  ...   \n",
       "\n",
       "    ZWILCH  ZWINT  ZXDA  ZXDB   ZXDC ZYG11A ZYG11B     ZYX  ZZEF1  ZZZ3  \n",
       "0     2.84   4.22  0.95  1.63  15.51   0.06   8.17  363.01  19.17  6.05  \n",
       "1     3.55  12.15   0.6  1.15  15.62   0.14    8.2   399.8  15.72  4.12  \n",
       "2     1.34   2.79  0.18  0.32  17.67   0.28   3.62  430.35  13.95  1.81  \n",
       "3     3.71   5.87   1.4  2.21  15.61   0.27   7.88  209.25  14.78  7.15  \n",
       "4     1.44   4.46  0.28  0.55   9.34   0.07   5.96  272.91   8.69   2.7  \n",
       "..     ...    ...   ...   ...    ...    ...    ...     ...    ...   ...  \n",
       "121   0.26   1.01  0.13  0.46   5.93   0.24   1.58  447.14   3.04   1.0  \n",
       "122   0.64   0.83  0.18  0.73   8.75   0.12   1.57  748.55   4.55  1.56  \n",
       "123   1.18   2.14  0.41  1.29  14.93   0.14   5.05  437.62  10.34  3.99  \n",
       "124   0.42   0.61  0.19  0.45   4.77   0.33   1.07  369.66   1.83  0.96  \n",
       "125   0.32   2.02  0.05   0.1   3.46    0.1   1.25  577.13   2.08  0.27  \n",
       "\n",
       "[126 rows x 18226 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the dataset contain 18226 features \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelEncoder for severity and sex\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used map function to label encode the Severity\n",
    "df2['Severity']= df2['Severity'].map({'ICU':1,'NonICU':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['Severity'] = label.fit_transform(df2['Severity'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Sex'] = label.fit_transform(df2['Sex'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    66\n",
       "0    60\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Severity</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.17</td>\n",
       "      <td>363.01</td>\n",
       "      <td>19.17</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>399.8</td>\n",
       "      <td>15.72</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.62</td>\n",
       "      <td>430.35</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.88</td>\n",
       "      <td>209.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.96</td>\n",
       "      <td>272.91</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  Sex  Severity  A1BG  A1CF   A2M A2ML1 A3GALT2 A4GALT A4GNT  ... ZWILCH  \\\n",
       "0  39    1         0  0.49   0.0  0.21  0.04    0.07    0.0  0.03  ...   2.84   \n",
       "1  63    1         0  0.29   0.0  0.14   0.0     0.0    0.0  0.05  ...   3.55   \n",
       "2  33    1         0  0.26   0.0  0.03  0.02     0.0    0.0  0.07  ...   1.34   \n",
       "3  49    1         0  0.45  0.01  0.09  0.07     0.0    0.0   0.0  ...   3.71   \n",
       "4  49    1         0  0.17   0.0   0.0  0.05    0.07    0.0   0.0  ...   1.44   \n",
       "\n",
       "   ZWINT  ZXDA  ZXDB   ZXDC ZYG11A ZYG11B     ZYX  ZZEF1  ZZZ3  \n",
       "0   4.22  0.95  1.63  15.51   0.06   8.17  363.01  19.17  6.05  \n",
       "1  12.15   0.6  1.15  15.62   0.14    8.2   399.8  15.72  4.12  \n",
       "2   2.79  0.18  0.32  17.67   0.28   3.62  430.35  13.95  1.81  \n",
       "3   5.87   1.4  2.21  15.61   0.27   7.88  209.25  14.78  7.15  \n",
       "4   4.46  0.28  0.55   9.34   0.07   5.96  272.91   8.69   2.7  \n",
       "\n",
       "[5 rows x 18226 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will create X, Y\n",
    "y = df2['Severity']\n",
    "x = df2.drop('Severity', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Applying PCA__ :\n",
    "\n",
    "In PCA or principal component analysis, its techique used to reduce the dimensionality of large data sets by transforming them into a smaller set of variables that retain most of the information found in the orginal dataset. Data sets with fewer variables naturally mean less accuracy, but the key to dimensionality reduction is to trade some accuracy for simplicity.\n",
    "\n",
    "\n",
    "We will be applying PCA on the Genes only, to do so, we will remove Sex and Age from the dataset and apply PCA then add them again.\n",
    "\n",
    "- the idea of applying PCA on the Genes only that Age and Gender are not correlated with the Genes features, and PCA will remove multi-collinearity between the Genes features which improves the interpretation of the parameters of the machine learning model.\n",
    "\n",
    "- PCA steps:\n",
    "\n",
    "    1- scaling the data\n",
    "    \n",
    "    2- compute the coveriance matrix\n",
    "    \n",
    "    3- compute the eigenvectors and eigenvalues from the coveraince matrix to constract the PCA components.\n",
    "\n",
    " Components are constructed in such a way that the first component represents the largest variance in the data set and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "..   ...\n",
       "121    1\n",
       "122    0\n",
       "123    0\n",
       "124    1\n",
       "125    1\n",
       "\n",
       "[126 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating catagerical dataframe for sex feature since we dont need to scale it\n",
    "df_sex=df2.Sex\n",
    "Sex_df = pd.DataFrame(df_sex, columns=['Sex'])\n",
    "Sex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will remove Sex from the dataset\n",
    "X = x.drop('Sex', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>18.92</td>\n",
       "      <td>4.07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.17</td>\n",
       "      <td>363.01</td>\n",
       "      <td>19.17</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>18.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>399.8</td>\n",
       "      <td>15.72</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.85</td>\n",
       "      <td>1.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.62</td>\n",
       "      <td>430.35</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.11</td>\n",
       "      <td>4.22</td>\n",
       "      <td>...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.88</td>\n",
       "      <td>209.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.96</td>\n",
       "      <td>272.91</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  A1BG  A1CF   A2M A2ML1 A3GALT2 A4GALT A4GNT   AAAS  AACS  ... ZWILCH  \\\n",
       "0  39  0.49   0.0  0.21  0.04    0.07    0.0  0.03  18.92  4.07  ...   2.84   \n",
       "1  63  0.29   0.0  0.14   0.0     0.0    0.0  0.05  18.68   3.0  ...   3.55   \n",
       "2  33  0.26   0.0  0.03  0.02     0.0    0.0  0.07  13.85  1.83  ...   1.34   \n",
       "3  49  0.45  0.01  0.09  0.07     0.0    0.0   0.0  22.11  4.22  ...   3.71   \n",
       "4  49  0.17   0.0   0.0  0.05    0.07    0.0   0.0   8.45  1.17  ...   1.44   \n",
       "\n",
       "   ZWINT  ZXDA  ZXDB   ZXDC ZYG11A ZYG11B     ZYX  ZZEF1  ZZZ3  \n",
       "0   4.22  0.95  1.63  15.51   0.06   8.17  363.01  19.17  6.05  \n",
       "1  12.15   0.6  1.15  15.62   0.14    8.2   399.8  15.72  4.12  \n",
       "2   2.79  0.18  0.32  17.67   0.28   3.62  430.35  13.95  1.81  \n",
       "3   5.87   1.4  2.21  15.61   0.27   7.88  209.25  14.78  7.15  \n",
       "4   4.46  0.28  0.55   9.34   0.07   5.96  272.91   8.69   2.7  \n",
       "\n",
       "[5 rows x 18224 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Applying MinMAX scaler to the dataset__ \n",
    "\n",
    "Note: we didnt remove Age feature since we need to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_n = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.566077</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.390123</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.638912</td>\n",
       "      <td>0.357671</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.538175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.087273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.556196</td>\n",
       "      <td>0.501894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435762</td>\n",
       "      <td>0.514175</td>\n",
       "      <td>0.303665</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.498053</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.641461</td>\n",
       "      <td>0.410926</td>\n",
       "      <td>0.787178</td>\n",
       "      <td>0.358473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.357349</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.112113</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.577882</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.455148</td>\n",
       "      <td>0.694167</td>\n",
       "      <td>0.143389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>0.244416</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.497664</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.614274</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>0.737782</td>\n",
       "      <td>0.640596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135035</td>\n",
       "      <td>0.155303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156291</td>\n",
       "      <td>0.183849</td>\n",
       "      <td>0.136126</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.253505</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.451147</td>\n",
       "      <td>0.227248</td>\n",
       "      <td>0.417761</td>\n",
       "      <td>0.226257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      A1BG  A1CF       A2M  A2ML1  A3GALT2  A4GALT     A4GNT  \\\n",
       "0  0.260870  0.160000   0.0  0.238636    0.4     0.04     0.0  0.157895   \n",
       "1  0.608696  0.087273   0.0  0.159091    0.0     0.00     0.0  0.263158   \n",
       "2  0.173913  0.076364   0.0  0.034091    0.2     0.00     0.0  0.368421   \n",
       "3  0.405797  0.145455   0.5  0.102273    0.7     0.00     0.0  0.000000   \n",
       "4  0.405797  0.043636   0.0  0.000000    0.5     0.04     0.0  0.000000   \n",
       "\n",
       "       AAAS      AACS  ...    ZWILCH     ZWINT      ZXDA      ZXDB      ZXDC  \\\n",
       "0  0.566077  0.704545  ...  0.341722  0.173540  0.486911  0.390123  0.493769   \n",
       "1  0.556196  0.501894  ...  0.435762  0.514175  0.303665  0.271605  0.498053   \n",
       "2  0.357349  0.280303  ...  0.143046  0.112113  0.083770  0.066667  0.577882   \n",
       "3  0.697406  0.732955  ...  0.456954  0.244416  0.722513  0.533333  0.497664   \n",
       "4  0.135035  0.155303  ...  0.156291  0.183849  0.136126  0.123457  0.253505   \n",
       "\n",
       "     ZYG11A    ZYG11B       ZYX     ZZEF1      ZZZ3  \n",
       "0  0.114286  0.638912  0.357671  0.968471  0.538175  \n",
       "1  0.342857  0.641461  0.410926  0.787178  0.358473  \n",
       "2  0.742857  0.252336  0.455148  0.694167  0.143389  \n",
       "3  0.714286  0.614274  0.135098  0.737782  0.640596  \n",
       "4  0.142857  0.451147  0.227248  0.417761  0.226257  \n",
       "\n",
       "[5 rows x 18224 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = pd.DataFrame(df_n, columns=X.columns)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age\n",
       "0  0.260870\n",
       "1  0.608696\n",
       "2  0.173913\n",
       "3  0.405797\n",
       "4  0.405797"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now after scaling Age and all the features, we will save it in seperate dataframe and remove it and then\n",
    "# apply PCA on Genes\n",
    "df_Age=df_norm.Age\n",
    "Age_df = pd.DataFrame(df_Age, columns=['Age'])\n",
    "Age_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing age\n",
    "df_norm = df_norm.drop('Age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.566077</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.390123</td>\n",
       "      <td>0.493769</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.638912</td>\n",
       "      <td>0.357671</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.538175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.556196</td>\n",
       "      <td>0.501894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435762</td>\n",
       "      <td>0.514175</td>\n",
       "      <td>0.303665</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.498053</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.641461</td>\n",
       "      <td>0.410926</td>\n",
       "      <td>0.787178</td>\n",
       "      <td>0.358473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.357349</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143046</td>\n",
       "      <td>0.112113</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.577882</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.455148</td>\n",
       "      <td>0.694167</td>\n",
       "      <td>0.143389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>0.244416</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.497664</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.614274</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>0.737782</td>\n",
       "      <td>0.640596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135035</td>\n",
       "      <td>0.155303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156291</td>\n",
       "      <td>0.183849</td>\n",
       "      <td>0.136126</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.253505</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.451147</td>\n",
       "      <td>0.227248</td>\n",
       "      <td>0.417761</td>\n",
       "      <td>0.226257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1BG  A1CF       A2M  A2ML1  A3GALT2  A4GALT     A4GNT      AAAS  \\\n",
       "0  0.160000   0.0  0.238636    0.4     0.04     0.0  0.157895  0.566077   \n",
       "1  0.087273   0.0  0.159091    0.0     0.00     0.0  0.263158  0.556196   \n",
       "2  0.076364   0.0  0.034091    0.2     0.00     0.0  0.368421  0.357349   \n",
       "3  0.145455   0.5  0.102273    0.7     0.00     0.0  0.000000  0.697406   \n",
       "4  0.043636   0.0  0.000000    0.5     0.04     0.0  0.000000  0.135035   \n",
       "\n",
       "       AACS  AADAC  ...    ZWILCH     ZWINT      ZXDA      ZXDB      ZXDC  \\\n",
       "0  0.704545    0.0  ...  0.341722  0.173540  0.486911  0.390123  0.493769   \n",
       "1  0.501894    0.0  ...  0.435762  0.514175  0.303665  0.271605  0.498053   \n",
       "2  0.280303    0.0  ...  0.143046  0.112113  0.083770  0.066667  0.577882   \n",
       "3  0.732955    0.0  ...  0.456954  0.244416  0.722513  0.533333  0.497664   \n",
       "4  0.155303    0.0  ...  0.156291  0.183849  0.136126  0.123457  0.253505   \n",
       "\n",
       "     ZYG11A    ZYG11B       ZYX     ZZEF1      ZZZ3  \n",
       "0  0.114286  0.638912  0.357671  0.968471  0.538175  \n",
       "1  0.342857  0.641461  0.410926  0.787178  0.358473  \n",
       "2  0.742857  0.252336  0.455148  0.694167  0.143389  \n",
       "3  0.714286  0.614274  0.135098  0.737782  0.640596  \n",
       "4  0.142857  0.451147  0.227248  0.417761  0.226257  \n",
       "\n",
       "[5 rows x 18223 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so now we have only genes remaining and we will apply PCA on it\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reduce the `18223`features of the Genes using PCA to 10 components which will contain information from all the genes features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_10 = pca_model.fit_transform(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639915498787619"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How much variance is explained by 10 principal components\n",
    "np.sum(pca_model.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10 PCA componants explains `66.3%` of the overall information. its recommended to have Number of components which explain 85% of the data variance, but since we have low number of observations (126 rows) we chooses 10 components to reduce the complixity of the model and avoid overfitting. its expected that the model will not have high accuracy with this information lost around `33.7% `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.467362</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>-9.123242</td>\n",
       "      <td>-8.964858</td>\n",
       "      <td>10.878133</td>\n",
       "      <td>8.738040</td>\n",
       "      <td>6.530395</td>\n",
       "      <td>0.937861</td>\n",
       "      <td>1.831448</td>\n",
       "      <td>2.200847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.156599</td>\n",
       "      <td>2.140342</td>\n",
       "      <td>-2.233645</td>\n",
       "      <td>-2.141676</td>\n",
       "      <td>-4.045874</td>\n",
       "      <td>6.582225</td>\n",
       "      <td>1.051435</td>\n",
       "      <td>2.202431</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>-4.035432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.840824</td>\n",
       "      <td>-6.565041</td>\n",
       "      <td>-9.089379</td>\n",
       "      <td>-3.601348</td>\n",
       "      <td>6.280681</td>\n",
       "      <td>-5.356577</td>\n",
       "      <td>5.406956</td>\n",
       "      <td>-2.949167</td>\n",
       "      <td>-0.478803</td>\n",
       "      <td>-5.584290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.537701</td>\n",
       "      <td>5.475659</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>5.666787</td>\n",
       "      <td>0.538421</td>\n",
       "      <td>4.321981</td>\n",
       "      <td>-1.336073</td>\n",
       "      <td>3.920340</td>\n",
       "      <td>0.228881</td>\n",
       "      <td>-0.457304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.624312</td>\n",
       "      <td>-13.858577</td>\n",
       "      <td>2.710596</td>\n",
       "      <td>-1.523001</td>\n",
       "      <td>6.754335</td>\n",
       "      <td>-4.476231</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>-1.710790</td>\n",
       "      <td>-2.456044</td>\n",
       "      <td>3.285687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1        PC2       PC3       PC4        PC5       PC6       PC7  \\\n",
       "0  19.467362   0.610147 -9.123242 -8.964858  10.878133  8.738040  6.530395   \n",
       "1  12.156599   2.140342 -2.233645 -2.141676  -4.045874  6.582225  1.051435   \n",
       "2  -5.840824  -6.565041 -9.089379 -3.601348   6.280681 -5.356577  5.406956   \n",
       "3  27.537701   5.475659  0.030296  5.666787   0.538421  4.321981 -1.336073   \n",
       "4  -2.624312 -13.858577  2.710596 -1.523001   6.754335 -4.476231  0.567991   \n",
       "\n",
       "        PC8       PC9      PC10  \n",
       "0  0.937861  1.831448  2.200847  \n",
       "1  2.202431  0.207123 -4.035432  \n",
       "2 -2.949167 -0.478803 -5.584290  \n",
       "3  3.920340  0.228881 -0.457304  \n",
       "4 -1.710790 -2.456044  3.285687  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df=pd.DataFrame(pca_10, columns=['PC1', 'PC2','PC3',\n",
    "                                      'PC4','PC5','PC6',\n",
    "                                      'PC7','PC8','PC9','PC10'])\n",
    "PCA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sex and age using the concat function \n",
    "X_final=pd.concat([PCA_df, Age_df, Sex_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.467362</td>\n",
       "      <td>0.610147</td>\n",
       "      <td>-9.123242</td>\n",
       "      <td>-8.964858</td>\n",
       "      <td>10.878133</td>\n",
       "      <td>8.738040</td>\n",
       "      <td>6.530395</td>\n",
       "      <td>0.937861</td>\n",
       "      <td>1.831448</td>\n",
       "      <td>2.200847</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.156599</td>\n",
       "      <td>2.140342</td>\n",
       "      <td>-2.233645</td>\n",
       "      <td>-2.141676</td>\n",
       "      <td>-4.045874</td>\n",
       "      <td>6.582225</td>\n",
       "      <td>1.051435</td>\n",
       "      <td>2.202431</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>-4.035432</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.840824</td>\n",
       "      <td>-6.565041</td>\n",
       "      <td>-9.089379</td>\n",
       "      <td>-3.601348</td>\n",
       "      <td>6.280681</td>\n",
       "      <td>-5.356577</td>\n",
       "      <td>5.406956</td>\n",
       "      <td>-2.949167</td>\n",
       "      <td>-0.478803</td>\n",
       "      <td>-5.584290</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.537701</td>\n",
       "      <td>5.475659</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>5.666787</td>\n",
       "      <td>0.538421</td>\n",
       "      <td>4.321981</td>\n",
       "      <td>-1.336073</td>\n",
       "      <td>3.920340</td>\n",
       "      <td>0.228881</td>\n",
       "      <td>-0.457304</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.624312</td>\n",
       "      <td>-13.858577</td>\n",
       "      <td>2.710596</td>\n",
       "      <td>-1.523001</td>\n",
       "      <td>6.754335</td>\n",
       "      <td>-4.476231</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>-1.710790</td>\n",
       "      <td>-2.456044</td>\n",
       "      <td>3.285687</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1        PC2       PC3       PC4        PC5       PC6       PC7  \\\n",
       "0  19.467362   0.610147 -9.123242 -8.964858  10.878133  8.738040  6.530395   \n",
       "1  12.156599   2.140342 -2.233645 -2.141676  -4.045874  6.582225  1.051435   \n",
       "2  -5.840824  -6.565041 -9.089379 -3.601348   6.280681 -5.356577  5.406956   \n",
       "3  27.537701   5.475659  0.030296  5.666787   0.538421  4.321981 -1.336073   \n",
       "4  -2.624312 -13.858577  2.710596 -1.523001   6.754335 -4.476231  0.567991   \n",
       "\n",
       "        PC8       PC9      PC10       Age  Sex  \n",
       "0  0.937861  1.831448  2.200847  0.260870    1  \n",
       "1  2.202431  0.207123 -4.035432  0.608696    1  \n",
       "2 -2.949167 -0.478803 -5.584290  0.173913    1  \n",
       "3  3.920340  0.228881 -0.457304  0.405797    1  \n",
       "4 -1.710790 -2.456044  3.285687  0.405797    1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Stratify sampling To avoid bias and imbalance spliting for target variable, which is the Severity, and gender in order to maintain the same distribution characteristics and balance of our target should be maintained in each split accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_final,y,test_size=0.2,random_state=0,stratify=Stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    52\n",
       "0    48\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14\n",
       "0    12\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here we have maintain the same balance distribution of the target feature in the train and test split which is around `52%` \n",
    "ICU and `48%` Non-ICU and the same for gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Processing Second Method feature selection using RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>18.92</td>\n",
       "      <td>...</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.17</td>\n",
       "      <td>363.01</td>\n",
       "      <td>19.17</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>18.68</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.2</td>\n",
       "      <td>399.8</td>\n",
       "      <td>15.72</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.62</td>\n",
       "      <td>430.35</td>\n",
       "      <td>13.95</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.88</td>\n",
       "      <td>209.25</td>\n",
       "      <td>14.78</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.96</td>\n",
       "      <td>272.91</td>\n",
       "      <td>8.69</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  Sex  A1BG  A1CF   A2M A2ML1 A3GALT2 A4GALT A4GNT   AAAS  ... ZWILCH  \\\n",
       "0  39    1  0.49   0.0  0.21  0.04    0.07    0.0  0.03  18.92  ...   2.84   \n",
       "1  63    1  0.29   0.0  0.14   0.0     0.0    0.0  0.05  18.68  ...   3.55   \n",
       "2  33    1  0.26   0.0  0.03  0.02     0.0    0.0  0.07  13.85  ...   1.34   \n",
       "3  49    1  0.45  0.01  0.09  0.07     0.0    0.0   0.0  22.11  ...   3.71   \n",
       "4  49    1  0.17   0.0   0.0  0.05    0.07    0.0   0.0   8.45  ...   1.44   \n",
       "\n",
       "   ZWINT  ZXDA  ZXDB   ZXDC ZYG11A ZYG11B     ZYX  ZZEF1  ZZZ3  \n",
       "0   4.22  0.95  1.63  15.51   0.06   8.17  363.01  19.17  6.05  \n",
       "1  12.15   0.6  1.15  15.62   0.14    8.2   399.8  15.72  4.12  \n",
       "2   2.79  0.18  0.32  17.67   0.28   3.62  430.35  13.95  1.81  \n",
       "3   5.87   1.4  2.21  15.61   0.27   7.88  209.25  14.78  7.15  \n",
       "4   4.46  0.28  0.55   9.34   0.07   5.96  272.91   8.69   2.7  \n",
       "\n",
       "[5 rows x 18225 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High-importance variables have a strong influence on outcome values, whereas low-importance variables might be left out, making the fit and prediction process simpler and faster. Choosing the top features based on importance means they are highly correlated with the target and not redundant which improve our model.\n",
    "\n",
    "- In the process of building a tree, the Gini impurity is used to determine which variables should be split at each node which means the selection of the top features will be based on __Gini importance (or mean decrease impurity)__.\n",
    "\n",
    "- Gini Impurity is measure how oftern a random chosen element would be incorrectly classified.\n",
    "\n",
    "-  In In random forests, the more a feature decreases the impurity, the more important the feature is. The impurity decrease from each feature can be averaged across trees to determine the top importance features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest consists of hundreds of decision trees, each tree constructed from a random extract of observations and features from the dataset. Not every tree sees all features and observations from the dataset. Since we have 18225 features its important to increase the number of trees so we would have covered all the features and generalize the features improtance which will be extracted from all the trees. I have choosen number of trees to be 10000, the disadvange of this choice is the computaional time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing RF, since we have high dimensional dataset we increases the number of trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RF=RandomForestClassifier(n_estimators=10000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10000, n_jobs=-1)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data on the RF\n",
    "model_RF.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the featuree importance\n",
    "feat_importances = pd.Series(model_RF.feature_importances_, index=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Since we have low number of observations (126 rows), We will select the top 15 features based in importance to simplfy our model and reduce the complixety, improve the performance and avoid overfitting__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the top 15 features based in importance\n",
    "features=pd.DataFrame(feat_importances.nlargest(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRR5L</td>\n",
       "      <td>0.003838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GALNT6</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARP3</td>\n",
       "      <td>0.003347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPR68</td>\n",
       "      <td>0.003323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBK1</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UBA7</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TMEM229B</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CD4</td>\n",
       "      <td>0.002664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OPTN</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARG1</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CYB561</td>\n",
       "      <td>0.002565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KLRG1</td>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TNIP3</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S1PR2</td>\n",
       "      <td>0.002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FCER1A</td>\n",
       "      <td>0.002349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index         0\n",
       "0      PRR5L  0.003838\n",
       "1     GALNT6  0.003453\n",
       "2      PARP3  0.003347\n",
       "3      GPR68  0.003323\n",
       "4       SBK1  0.003189\n",
       "5       UBA7  0.003095\n",
       "6   TMEM229B  0.002757\n",
       "7        CD4  0.002664\n",
       "8       OPTN  0.002634\n",
       "9       ARG1  0.002610\n",
       "10    CYB561  0.002565\n",
       "11     KLRG1  0.002487\n",
       "12     TNIP3  0.002405\n",
       "13     S1PR2  0.002385\n",
       "14    FCER1A  0.002349"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        PRR5L\n",
       "1       GALNT6\n",
       "2        PARP3\n",
       "3        GPR68\n",
       "4         SBK1\n",
       "5         UBA7\n",
       "6     TMEM229B\n",
       "7          CD4\n",
       "8         OPTN\n",
       "9         ARG1\n",
       "10      CYB561\n",
       "11       KLRG1\n",
       "12       TNIP3\n",
       "13       S1PR2\n",
       "14      FCER1A\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to select the columns names \n",
    "top_features=features['index']\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now selecting the  15 features from x which contain 18225 features\n",
    "X_final_RF=x[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRR5L</th>\n",
       "      <th>GALNT6</th>\n",
       "      <th>PARP3</th>\n",
       "      <th>GPR68</th>\n",
       "      <th>SBK1</th>\n",
       "      <th>UBA7</th>\n",
       "      <th>TMEM229B</th>\n",
       "      <th>CD4</th>\n",
       "      <th>OPTN</th>\n",
       "      <th>ARG1</th>\n",
       "      <th>CYB561</th>\n",
       "      <th>KLRG1</th>\n",
       "      <th>TNIP3</th>\n",
       "      <th>S1PR2</th>\n",
       "      <th>FCER1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.8</td>\n",
       "      <td>10.67</td>\n",
       "      <td>7.13</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.27</td>\n",
       "      <td>118.12</td>\n",
       "      <td>29.49</td>\n",
       "      <td>184.46</td>\n",
       "      <td>23.56</td>\n",
       "      <td>26.52</td>\n",
       "      <td>9.29</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.37</td>\n",
       "      <td>11.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.72</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.32</td>\n",
       "      <td>59.82</td>\n",
       "      <td>6.03</td>\n",
       "      <td>78.82</td>\n",
       "      <td>15.79</td>\n",
       "      <td>109.8</td>\n",
       "      <td>11.22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>23.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.19</td>\n",
       "      <td>96.52</td>\n",
       "      <td>6.32</td>\n",
       "      <td>32.52</td>\n",
       "      <td>17.46</td>\n",
       "      <td>123.78</td>\n",
       "      <td>11.01</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.2</td>\n",
       "      <td>7.09</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.52</td>\n",
       "      <td>61.91</td>\n",
       "      <td>10.96</td>\n",
       "      <td>108.4</td>\n",
       "      <td>29.42</td>\n",
       "      <td>9.31</td>\n",
       "      <td>10.41</td>\n",
       "      <td>24.14</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.44</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>49.13</td>\n",
       "      <td>10.32</td>\n",
       "      <td>15.69</td>\n",
       "      <td>11.07</td>\n",
       "      <td>43.66</td>\n",
       "      <td>6.51</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.88</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRR5L GALNT6 PARP3 GPR68  SBK1    UBA7 TMEM229B     CD4   OPTN    ARG1  \\\n",
       "0   8.8  10.67  7.13  1.68  3.27  118.12    29.49  184.46  23.56   26.52   \n",
       "1  7.72   4.53  3.11  3.43  2.32   59.82     6.03   78.82  15.79   109.8   \n",
       "2   4.0   2.43  3.96  1.59  1.19   96.52     6.32   32.52  17.46  123.78   \n",
       "3  18.2   7.09  3.12  4.02  3.52   61.91    10.96   108.4  29.42    9.31   \n",
       "4  7.44   1.34  1.99  1.71  0.61   49.13    10.32   15.69  11.07   43.66   \n",
       "\n",
       "  CYB561  KLRG1 TNIP3 S1PR2 FCER1A  \n",
       "0   9.29   7.98  0.38  3.37  11.02  \n",
       "1  11.22   12.0  0.41  1.29  23.93  \n",
       "2  11.01   5.02  0.29  1.03  10.86  \n",
       "3  10.41  24.14  0.58  1.75   91.8  \n",
       "4   6.51  11.22  0.39  0.88  12.07  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_RF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to standardize the data before fitting it to SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=scale.fit_transform(X_final_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=pd.DataFrame(X_scaled,columns=X_final_RF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRR5L</th>\n",
       "      <th>GALNT6</th>\n",
       "      <th>PARP3</th>\n",
       "      <th>GPR68</th>\n",
       "      <th>SBK1</th>\n",
       "      <th>UBA7</th>\n",
       "      <th>TMEM229B</th>\n",
       "      <th>CD4</th>\n",
       "      <th>OPTN</th>\n",
       "      <th>ARG1</th>\n",
       "      <th>CYB561</th>\n",
       "      <th>KLRG1</th>\n",
       "      <th>TNIP3</th>\n",
       "      <th>S1PR2</th>\n",
       "      <th>FCER1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619888</td>\n",
       "      <td>3.583725</td>\n",
       "      <td>2.876934</td>\n",
       "      <td>-0.323332</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>2.922674</td>\n",
       "      <td>3.922179</td>\n",
       "      <td>3.027633</td>\n",
       "      <td>0.690113</td>\n",
       "      <td>-0.718651</td>\n",
       "      <td>0.756207</td>\n",
       "      <td>-0.280065</td>\n",
       "      <td>0.663619</td>\n",
       "      <td>3.451970</td>\n",
       "      <td>-0.318999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383799</td>\n",
       "      <td>0.595459</td>\n",
       "      <td>0.470287</td>\n",
       "      <td>0.680253</td>\n",
       "      <td>0.356536</td>\n",
       "      <td>0.453365</td>\n",
       "      <td>-0.099105</td>\n",
       "      <td>0.581315</td>\n",
       "      <td>-0.144385</td>\n",
       "      <td>-0.404538</td>\n",
       "      <td>1.219558</td>\n",
       "      <td>0.104136</td>\n",
       "      <td>0.804307</td>\n",
       "      <td>0.280616</td>\n",
       "      <td>0.261838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.429393</td>\n",
       "      <td>-0.426586</td>\n",
       "      <td>0.979155</td>\n",
       "      <td>-0.374944</td>\n",
       "      <td>-0.332812</td>\n",
       "      <td>2.007802</td>\n",
       "      <td>-0.049396</td>\n",
       "      <td>-0.490859</td>\n",
       "      <td>0.034973</td>\n",
       "      <td>-0.351809</td>\n",
       "      <td>1.169141</td>\n",
       "      <td>-0.562959</td>\n",
       "      <td>0.241553</td>\n",
       "      <td>-0.115804</td>\n",
       "      <td>-0.326197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.674729</td>\n",
       "      <td>1.841381</td>\n",
       "      <td>0.476274</td>\n",
       "      <td>1.018604</td>\n",
       "      <td>1.088586</td>\n",
       "      <td>0.541888</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>1.266303</td>\n",
       "      <td>1.319476</td>\n",
       "      <td>-0.783563</td>\n",
       "      <td>1.025095</td>\n",
       "      <td>1.264384</td>\n",
       "      <td>1.601543</td>\n",
       "      <td>0.981973</td>\n",
       "      <td>3.315395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322591</td>\n",
       "      <td>-0.957076</td>\n",
       "      <td>-0.200221</td>\n",
       "      <td>-0.306127</td>\n",
       "      <td>-0.686636</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.636245</td>\n",
       "      <td>-0.880593</td>\n",
       "      <td>-0.651312</td>\n",
       "      <td>-0.654003</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>0.029590</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>-0.344507</td>\n",
       "      <td>-0.271758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PRR5L    GALNT6     PARP3     GPR68      SBK1      UBA7  TMEM229B  \\\n",
       "0  0.619888  3.583725  2.876934 -0.323332  0.936075  2.922674  3.922179   \n",
       "1  0.383799  0.595459  0.470287  0.680253  0.356536  0.453365 -0.099105   \n",
       "2 -0.429393 -0.426586  0.979155 -0.374944 -0.332812  2.007802 -0.049396   \n",
       "3  2.674729  1.841381  0.476274  1.018604  1.088586  0.541888  0.745947   \n",
       "4  0.322591 -0.957076 -0.200221 -0.306127 -0.686636  0.000588  0.636245   \n",
       "\n",
       "        CD4      OPTN      ARG1    CYB561     KLRG1     TNIP3     S1PR2  \\\n",
       "0  3.027633  0.690113 -0.718651  0.756207 -0.280065  0.663619  3.451970   \n",
       "1  0.581315 -0.144385 -0.404538  1.219558  0.104136  0.804307  0.280616   \n",
       "2 -0.490859  0.034973 -0.351809  1.169141 -0.562959  0.241553 -0.115804   \n",
       "3  1.266303  1.319476 -0.783563  1.025095  1.264384  1.601543  0.981973   \n",
       "4 -0.880593 -0.651312 -0.654003  0.088791  0.029590  0.710515 -0.344507   \n",
       "\n",
       "     FCER1A  \n",
       "0 -0.318999  \n",
       "1  0.261838  \n",
       "2 -0.326197  \n",
       "3  3.315395  \n",
       "4 -0.271758  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is standardize and ready for SVC machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data based on Stratify sampling\n",
    "X2_train,X2_test,y2_train,y2_test=train_test_split(X_scaled,y,test_size=0.2,stratify=Stratify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training and tuning for first method PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready for machine learning, below will be implementation of Support vector machine classifier.\n",
    "Note that I applied Logistic regression, Decison tree, Random Forest, XGboost and SVC and i chooses the model which have the highest accuracy in consider of bais-variance trade off. \n",
    "\n",
    "The below observation was taken in consideration choosing the best model:\n",
    "- Decison Tree, RandomForest,XGboost classifiers were overfitting (train score 1.0 and test score was much lower).\n",
    "- Logistic Regression model was underfit and accuracy was low which means it didnt catch the true pattern.\n",
    "- SVC have the best accuracy among the others and training score was closer to the test score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now applying SVC__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal with SVC is to create the best separating hyperplane to seperate the data into two classes ICU and NonICU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "SV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 76.92307692307693 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy:',accuracy_score(y_test,y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 87.0 %\n",
      "test score: 76.92307692307693 %\n"
     ]
    }
   ],
   "source": [
    "print('Training score:',SV.score(X_train,y_train)*100,'%')\n",
    "print('test score:',SV.score(X_test,y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy is `87 %` and the test accuracy is `76.9%`. which means the model tend to overfit since we have around 11% difference in accuracy between the test and train accuracy __(which is the variance)__. So we will tune the hyperparameters in order to reduce the difference between train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters for SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In SVC, There are 3 important hyperparameters which can be tuned to improve the model score. \n",
    "- `Kernel` parameter is used to separate the data by selecting the type of hyperplane. There are 4 types of hyperplanes that we can use to fit our model but we will use RBF kernel and linear since they are the most used one.\n",
    "- `Gamma` gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.\n",
    "- `C` Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty. It is common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly.\n",
    "\n",
    "We will use GridSearchCV method, which will choose the right set of parameters to tune our model by running all possible scenarios after feeding the range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_param_grid = {'C': [0.01,0.1,1,10,50], 'gamma': ['scale','auto',0.01,0.001,], 'kernel': ['rbf','linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search to tune the hyperparameters\n",
    "grid = GridSearchCV(estimator=SVC(),param_grid= my_param_grid, refit = True, verbose=2, cv=5,scoring='accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   1.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.3s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.2s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.9s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 50],\n",
       "                         'gamma': ['scale', 'auto', 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'linear']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below are the best parameters used to build the best accuracy model\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy after tuning: 76.92307692307693 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy after tuning:',grid.score(X_test,y_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy didnt imporve even after tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training and tuning for Second method feature selection from RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRR5L</th>\n",
       "      <th>GALNT6</th>\n",
       "      <th>PARP3</th>\n",
       "      <th>GPR68</th>\n",
       "      <th>SBK1</th>\n",
       "      <th>UBA7</th>\n",
       "      <th>TMEM229B</th>\n",
       "      <th>CD4</th>\n",
       "      <th>OPTN</th>\n",
       "      <th>ARG1</th>\n",
       "      <th>CYB561</th>\n",
       "      <th>KLRG1</th>\n",
       "      <th>TNIP3</th>\n",
       "      <th>S1PR2</th>\n",
       "      <th>FCER1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.864407</td>\n",
       "      <td>-0.742933</td>\n",
       "      <td>-0.942570</td>\n",
       "      <td>-0.942686</td>\n",
       "      <td>-0.875749</td>\n",
       "      <td>-0.630928</td>\n",
       "      <td>-0.973297</td>\n",
       "      <td>-0.948212</td>\n",
       "      <td>-1.133538</td>\n",
       "      <td>2.452614</td>\n",
       "      <td>-1.272451</td>\n",
       "      <td>-0.815270</td>\n",
       "      <td>-0.743268</td>\n",
       "      <td>-0.649445</td>\n",
       "      <td>-0.800855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.794455</td>\n",
       "      <td>-0.684531</td>\n",
       "      <td>-0.284035</td>\n",
       "      <td>-0.610070</td>\n",
       "      <td>-0.448720</td>\n",
       "      <td>-0.436094</td>\n",
       "      <td>-0.623620</td>\n",
       "      <td>-0.894951</td>\n",
       "      <td>-0.445104</td>\n",
       "      <td>-0.475523</td>\n",
       "      <td>-0.218509</td>\n",
       "      <td>-0.504660</td>\n",
       "      <td>-0.930853</td>\n",
       "      <td>-0.451236</td>\n",
       "      <td>-0.746416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619888</td>\n",
       "      <td>3.583725</td>\n",
       "      <td>2.876934</td>\n",
       "      <td>-0.323332</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>2.922674</td>\n",
       "      <td>3.922179</td>\n",
       "      <td>3.027633</td>\n",
       "      <td>0.690113</td>\n",
       "      <td>-0.718651</td>\n",
       "      <td>0.756207</td>\n",
       "      <td>-0.280065</td>\n",
       "      <td>0.663619</td>\n",
       "      <td>3.451970</td>\n",
       "      <td>-0.318999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.230467</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>-0.631263</td>\n",
       "      <td>-0.529783</td>\n",
       "      <td>-0.186402</td>\n",
       "      <td>-0.746134</td>\n",
       "      <td>-0.275658</td>\n",
       "      <td>0.922420</td>\n",
       "      <td>-0.290449</td>\n",
       "      <td>-0.536852</td>\n",
       "      <td>-0.319342</td>\n",
       "      <td>-0.477900</td>\n",
       "      <td>-0.790164</td>\n",
       "      <td>-0.329260</td>\n",
       "      <td>0.870120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.785711</td>\n",
       "      <td>-0.665063</td>\n",
       "      <td>-0.164301</td>\n",
       "      <td>-0.489640</td>\n",
       "      <td>-0.351113</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>-0.633905</td>\n",
       "      <td>-0.473028</td>\n",
       "      <td>-0.521358</td>\n",
       "      <td>0.234060</td>\n",
       "      <td>-0.828307</td>\n",
       "      <td>-0.566782</td>\n",
       "      <td>-0.555683</td>\n",
       "      <td>-0.542717</td>\n",
       "      <td>-0.792757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRR5L    GALNT6     PARP3     GPR68      SBK1      UBA7  TMEM229B  \\\n",
       "27 -0.864407 -0.742933 -0.942570 -0.942686 -0.875749 -0.630928 -0.973297   \n",
       "65 -0.794455 -0.684531 -0.284035 -0.610070 -0.448720 -0.436094 -0.623620   \n",
       "0   0.619888  3.583725  2.876934 -0.323332  0.936075  2.922674  3.922179   \n",
       "45 -0.230467  0.021167 -0.631263 -0.529783 -0.186402 -0.746134 -0.275658   \n",
       "94 -0.785711 -0.665063 -0.164301 -0.489640 -0.351113  0.079369 -0.633905   \n",
       "\n",
       "         CD4      OPTN      ARG1    CYB561     KLRG1     TNIP3     S1PR2  \\\n",
       "27 -0.948212 -1.133538  2.452614 -1.272451 -0.815270 -0.743268 -0.649445   \n",
       "65 -0.894951 -0.445104 -0.475523 -0.218509 -0.504660 -0.930853 -0.451236   \n",
       "0   3.027633  0.690113 -0.718651  0.756207 -0.280065  0.663619  3.451970   \n",
       "45  0.922420 -0.290449 -0.536852 -0.319342 -0.477900 -0.790164 -0.329260   \n",
       "94 -0.473028 -0.521358  0.234060 -0.828307 -0.566782 -0.555683 -0.542717   \n",
       "\n",
       "      FCER1A  \n",
       "27 -0.800855  \n",
       "65 -0.746416  \n",
       "0  -0.318999  \n",
       "45  0.870120  \n",
       "94 -0.792757  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27     1\n",
       "65     1\n",
       "0      0\n",
       "45     1\n",
       "94     0\n",
       "      ..\n",
       "82     1\n",
       "76     0\n",
       "116    1\n",
       "71     0\n",
       "23     1\n",
       "Name: Severity, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 90.0 %\n",
      "test score: 96.15384615384616 %\n"
     ]
    }
   ],
   "source": [
    "print('Training score:',model.score(X2_train,y2_train)*100,'%')\n",
    "print('test score:',model.score(X2_test,y2_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here, train accuracy is 90% while test accuracy is 96%.\n",
    "Test accuary should be lower than train accuary beacause the model was learning the pattern from the train data and test accuary should be lower since the model have not seen the test data. however,Usually we dont put final conclusions until we perform Kfold cross validation and see the average accuracy which give better validation.\n",
    "\n",
    "another reason why we have test accuarcy is higher than the train is that the test samples is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_param_grid = {'C': [0.01,0.1,1,10,50], 'gamma': ['scale','auto',0.01,0.001,], 'kernel': ['rbf','linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = GridSearchCV(estimator=SVC(),param_grid= my_param_grid, refit = True, verbose=2, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.01, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.01, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=50, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=50, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=50, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=50, gamma=0.001, kernel=linear; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 50],\n",
       "                         'gamma': ['scale', 'auto', 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'linear']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below are the best parameters used to build the best accuracy model\n",
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy after tuning: 96.15384615384616 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy after tuning:',grid2.score(X2_test,y2_test)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy didnt imporve even after tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model validation for PCA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After training and tuning the model, we will validate our model accuracy using `Cross_val_score ` which will split the data into several k-folds with different splits and measure the model accuracy according to each split, then calculate the average accuracy score for all the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters for PCA model\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and refil it with the tuned hyperparameters obtained from previous section for PCA model\n",
    "SVC_cv=SVC(C=1,gamma='scale',kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the KFold Cross-Validation\n",
    "SV_CV=cross_val_score(SVC_cv,X_final, y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV average model score: 80.06410256410257 %\n"
     ]
    }
   ],
   "source": [
    "print('CV average model score:',(SV_CV.mean())*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the avarge accuarcy of PCA model is `80%` which is closer to the accuracy we got after tuning PCA model `76.9%` and give overall accuracy performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model validation for RF feature selection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training and tuning second model, we will validate our model accuracy using Cross_val_score which will split the data into several k-folds with different splits and measure the model accuracy according to each split, then calculate the average accuracy score for all the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters for PCA model\n",
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the model with the tuned hyperparameters\n",
    "SVC_CV=SVC(C=10,gamma=0.01,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the KFold Cross-Validation\n",
    "result=cross_val_score(SVC_CV,X_scaled,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for Cross-Validation K-Fold  87.24358974358975 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy for Cross-Validation K-Fold \",(result.mean())*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the avarge accuarcy of the model is `87.2%` which give overall accuracy performance of our model on unseen data. so here we can put final conclusion about train accuarcy `90%` and test accuracy of the model and we can see the train accuracy is higher than the test accuarcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 PCA model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model overall average accuracy by cross-validation is `80% `which is expected since we have information lost becasue we have only selected 10 PCA componants which are explaining `66.3%`. To have better model we need to have higher infromation obtained from PCA (more PCA compoinants which explained more variance) and more number of observations to train our model, and since we have very low observations compared to the features, we try to minimize the selected features from PCA in order to avoid model overfitting and minimizing the model complixity (introduced bais in order to have better overall variance)\n",
    "\n",
    "- as conclusion, there is quit difference between train accuracy and cross validation accuracy (which is the variance), which means our model tend to be overfitted and the closer the difference the better the model.\n",
    "\n",
    "-The SVM kernel used in PCA model was Radial Basis Function (RBF) kernel which indicate that the data is not linearly separable, which transform the training data to higher dimension so that a non-linear decision surface can be transformed to a linear equation and be able to classfiy the training data into ICU and NonICU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature selection from RF model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model overall average accuracy by cross-validation is `87.2% ` and the training accuracy is `90%` which indicate that the model is fit since the variance which is difference between training accuarcy and cross validation accuracy is close which means the model are generalizing well.\n",
    "\n",
    "-The SVM kernel used in Feature selection from RF model was Radial Basis Function (RBF) kernel which indicate that the data is not linearly separable, which transform the training data to higher dimension so that a non-linear decision surface can be transformed to a linear equation and be able to classfiy the training data into ICU and NonICU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 PCA model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix,recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict new unseen data (X_test)\n",
    "grid_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Confusion_matrix is used to show summarized result of Prediction vs Actual values and it quick way to see where our model misclassify in while making predictions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "plot_confusion_matrix(grid,X_test,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model have correctly classify `20` observation out of `26` and we can see the accuracy of the model = (total correct classification/ total observations)*100 =(20/26)*100= `77%`\n",
    "- `True Negative (TN)`: The model has predicted correctly 10 observations as NON-ICU \n",
    "- `True Positive (TP)`: The model has predicted correctly 10 observations as ICU \n",
    "- `False Positive (FP)`:The model has predicted 2 observations as ICU while they are NON-ICU\n",
    "- `False Negative (FN)`:The model has predicted 4 observations as NON-ICU while they are ICU.\n",
    "\n",
    "Based on this objective, its critical to misclassify the ICU as NON-ICU, and our model should have lower FN.\n",
    "\n",
    "`Misclassification Rate`: it describe how often our model is wrong in prediction the classification. this rate should be lower to have better model.\n",
    "Misclassification Rate=((FP+FN)/total)*100= `23%`\n",
    "- `Precision`: its a measure how often the model is correct when it predict ICU or 1: (TP/Predicted ICU)=10/12=`0.83`\n",
    "- `recall`: its a measure of how often the model predict ICU  when its acually ICU: (TP/actual ICU)=10/14= `0.71`\n",
    "the higher the recall the better the model.\n",
    "- `F1 score`: is the harmonic mean of the precision and recall =Precision*recall/(Precision+recall)=`0.71`\n",
    "the higher F1 score is the better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77        12\n",
      "           1       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.77      0.77      0.77        26\n",
      "weighted avg       0.78      0.77      0.77        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of the PCA model\n",
    "round(accuracy_score(y_test,grid_pred) ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision_score for PCA model\n",
    "round(precision_score(y_test,grid_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall_score for PCA model\n",
    "round(recall_score(y_test,grid_pred),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_score for PCA model\n",
    "round(f1_score(y_test,grid_pred),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 feature selection from RF model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction = grid2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Confusion_matrix is used to show summarized result of Prediction vs Actual values and it quick way to see where our model misclassify in while making predictions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion_matrix\n",
    "plot_confusion_matrix(grid2,X2_test,y2_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.97      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test,grid_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model have correctly classify `25` observation out of `26` and we can see the accuracy of the model = (total correct classification/ total observations)*100 =(25/26)*100= `96%`\n",
    "- `True Negative (TN)`: The model has predicted correctly 11 observations as NON-ICU \n",
    "- `True Positive (TP)`: The model has predicted correctly 14 observations as ICU \n",
    "- `False Positive (FP)`:The model has predicted 1 observations as ICU while they are NON-ICU.\n",
    "- `False Negative (FN)`:The model has predicted 0 observations as NON-ICU while they are ICU.\n",
    "\n",
    "Based on this objective, its critical to misclassify the ICU as NON-ICU, and our model have zero FN.\n",
    "\n",
    "`Misclassification Rate`: it describe how often our model is wrong in prediction the classification. this rate should be lower to have better model.\n",
    "Misclassification Rate=((FP+FN)/total)*100= `3.8%`\n",
    "- `Precision`: its a measure how often the model is correct when it predict ICU or 1: (TP/Predicted ICU)=14/15=`0.93`\n",
    "- `recall`: its a measure of how often the model predict ICU  when its acually ICU: (TP/actual ICU)=14/14= `1`\n",
    "the higher the recall the better the model.\n",
    "- `F1 score`: is the harmonic mean of the precision and recall =Precision*recall/(Precision+recall)=`0.96`\n",
    "the higher F1 score is the better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "Below is the summarized steps used to implement the model:\n",
    "- EDA analysis and cleaning the data\n",
    "- first method PCA:\n",
    "    - Applying PCA in order to Reduce the dimensions of the dataset to simplify the model and reduce the complexity.\n",
    "- Second method (feature selection from RF)\n",
    "- Splitting the data with taking in considration the characteristics or attributes of the members in Gender and Severity using Stratify sampling technique.\n",
    "- Applying SVM classifier on our data.\n",
    "- Tuning the hyperparameters.\n",
    "- validating our accuracy using KFold cross-validation technique.\n",
    "- making predictions on unseen data.\n",
    "\n",
    "As discussed earlier, reducing the dataset dimensions using PCA is useful for simplifying our model, reducing the computational time and complexity, and avoiding overfitting. \n",
    "To build a good model, we should select PCA components that contain most of the data information. The recommended choosing PCA components that explain 85% of the variance, but since we have a low number of observations, we selected 10 components that explained 66% of the variance to avoid increasing the complexity of the model. Because of information lost by selecting only 10 components our model performance or accuracy was 76%. Comparing the PCA method to the Random Forest method, the PCA method is faster to implement when considering computational time for PCA and Random Forest algorithms. On the other hand, if we look to build an accurate model, selecting the top features from Random Forest which are highly correlated with the target variable and not redundant improved the accuracy of the model and generalized well.\n",
    "\n",
    "The main limitations of RandomForest is that it have high computaional time when we select large number of trees and correlated features will be given similar and lowered importance, compared to what their importance would be if the tree was built without correlated counterparts. While PCA remove the multi-collinearity between independent features.\n",
    "\n",
    "- So the best way is to choose top features extracted by RF and check the correlated features using correlation matrix and manually remove the correlated features.\n",
    "\n",
    "SVM algorthim will not perform well in large dataset, but since we have low number of observations and we reduced the dimension of the dataset its a good choice to be used compared to other algorthims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 PCA model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To analyze or evaluate the cost of implementating our machine learning model or the complexity of our code, we need to take in consideration the O notation of PCA implementation and the SVC algorithm.\n",
    "- For PCA, the algorithm have two main computational steps:\n",
    "    1- Computing Covariance matrix with O notation=  `O(p^2)*n)`\n",
    "    2- Computing the eigenvalue decomposition in term of O notation= `O(p^3)`\n",
    "    thus,the complexity of PCA is `O(min(p^3,n^3))` where `n` is the number of training observations and `p` is the number of features. the complexity will grow in polynomial for both features and observations.\n",
    "- For SVM, training complexity or time in SVM algorithm= `O((n^2)*p+n^3)`,thus the complexity is assumed to be `O(n^3)` where `n` is the number of training observations and `p` is the number of features.\n",
    "- which means the training time is polynomial and would grow very fast if we have more number of samples. since we have low number of samples, the choice of choosing SVC would be good.\n",
    "\n",
    "- below are the computational time for PCA and training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for PCA\n",
    "start1 = time.time()\n",
    "\n",
    "pca_model = PCA(n_components=10)\n",
    "pca_10 = pca_model.fit_transform(df_norm)\n",
    "\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above PCA is : 0.26749658584594727 second\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above PCA is :\", end1-start1,'second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational time for SVC to train the model\n",
    "start2 = time.time()\n",
    "\n",
    "SV.fit(X_train,y_train)\n",
    "\n",
    "end2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above SVC traing is : 0.008005380630493164 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above SVC traing is :\", end2-start2,'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 feature selection from RF model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To analyze or evaluate the cost of implementating our machine learning model or the complexity of our code, we need to take in consideration the O notation of RandomForest algorithm and the SVC algorithm since we use RF as feature selection and build the model using SVM.\n",
    "\n",
    "- For RandomForest, the algorithm complexity depend on two factors, number of trees `(ntree)` and number of features `(p)`.\n",
    "\n",
    "- training complexity or time in RF algorithm by O notation=  `O((n^2)*p*ntree))` where `n` is number of training observations.\n",
    "- Run-time Complexity=O(depth of tree* ntree).\n",
    " \n",
    "- For SVM, training complexity or time in SVM algorithm= `O(n^2p+n^3)`,thus the complexity is assumed to be `O(n^3)` where `n` is the number of training observations and `p` is the number of features.\n",
    "- which means the training time is polynomial and would grow very fast if we have more number of samples. since we have low number of samples, the choice of choosing SVC would be good.\n",
    "\n",
    "- below are the computational time for RF and SVC training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational time for RF to select the features\n",
    "start3 = time.time()\n",
    "\n",
    "model_RF.fit(x,y)\n",
    "\n",
    "end3 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above RF is : 19.97100281715393 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above RF is :\", end3-start3,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computational time for SVC to train the model\n",
    "start4 = time.time()\n",
    "model.fit(X2_train,y2_train)\n",
    "end4 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above SVC traing is : 0.007978677749633789 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above SVC traing is :\", end4-start4,'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
